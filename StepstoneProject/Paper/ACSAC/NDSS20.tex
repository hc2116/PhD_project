\documentclass[runningheads,11pt]{llncs}
\usepackage[]{graphicx}
\usepackage[]{color}
\usepackage[margin=1.4in]{geometry}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage[cmex10]{amsmath}
\usepackage{multirow}
\usepackage{makecell}
%\usepackage{tikz}
%\usetikzlibrary{shapes}
%\usepackage{amsmath}
%\usepackage{xspace}
%\newcommand{\A}{\ensuremath{\mathcal{A}}\xspace}
%\newcommand{\B}{\ensuremath{\mathcal{B}}\xspace}
%\newcommand\pa[1]{\ensuremath{\left(#1\right)}}
%\usepackage{caption} 
%\captionsetup[table]{skip=3pt}

\hyphenation{op-tical net-works semi-conduc-tor}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\title{Evading stepping stone detection by using enough chaff perturbations}
%Evaluation of passiv stepping stone detection techniques under chaff and delay}

%\hspace{\columnsep}\makebox[\columnwidth]{}}


\maketitle     

\begin{abstract}

....

....

....

....
\end{abstract}



\section{Introduction}\label{Sec:Introduction}

%\textcolor{red}{Network attackers frequently use a chain of compromised intermediate nodes to attack a target machine and maintain anonymity. This chain of nodes between the attacker and the target is calleda stepping stone chain. }

The problem of stepping-stones detection (SSD) has been studied for over 20 years, yet the body of literature fails at providing an informative overview of the detection capabilities of current methods. In this paper, we set out to do just that by evaluating and comparing a number of selected state-of-the-art approaches on a new and independently generated dataset.

%Malicious actors on the Internet frequently use chains of compromised hosts, called stepping-stones, to relay their attack in order to obtain access to restricted resources and to reduce the chance of being detected. 

In a stepping-stone attack, malicious commands are relayed via a chain of compromised hosts, called stepping-stones, in order to access restricted resources and reduce the chance of being traced back. \textcolor{black}{Real-world attacks using stepping-stone chains include the Operation Aurora \cite{tankard2011advanced}, the Operation Night Dragon \cite{mcafee2015report}, the Black Energy \cite{eisac2017report} on the Ukrainian powergrid, and the MEDJACK \cite{ayala2016active} attack where medical devices were used as stepping-stones.} The infamous Archimedes tool \cite{archimedes2017} used by the CIA leverages stepping-stone chains to reach the LAN of target hosts, while the emergence of IoT-devices further increases the attack surface via connected printers, cameras, or even thermostats \textcolor{red}{insert citation from Infosec Resources, 2019}.

%Attackers typically begin by compromising any vulnerable internal host and then try to move deeper into the network to reach the most valuable targets \cite{Mandiant2015trends}. 

%Malicious actors on the Internet frequently use chains of compromised hosts to relay their attack, in order to obtain access to restricted resources and to reduce the chance of being detected. Attackers typically begin by compromising any vulnerable internal host, called a foothold, and then try to move deeper into the network to reach the most valuable targets \cite{Mandiant2015trends}.

%For this, a technique called \textit{pivoting}\footnote{also called \textit{island hopping}} is used where commands are moved via compromised hosts, called \textbf{stepping-stones}, to the target using a command propagation tunnel \cite{cisco2014report}.
%, are used by the attacker as relay machines, to which they maintain access using tools such as SSH or Telnet. 
%Furthermore, accessing a target via multiple relayed TCP connections can make it hard to tell the intruder's geographical location, and enables attackers to hide behind a long interactive stepping-stone chain. For this reason, attacks involving stepping-stone chains are often called multi-layered attacks. %Furthermore, it is often required to relay an attack via privileged hosts in a network that have access to restricted resources. 
 %To hide correlation between relayed packets, intruders can impose delays on packet transfer and inject additional \textit{chaff} packets into the connections.

%Unaware pivoters propagate malicious commands to the last host of the pivoting chain and return the results to the initial host. The terminal host can either represent the final target or be used by attackers to further increase the length of the pivoting tunnel. 

The detection of interactive stepping-stones is challenging due to various reasons. Attackers are not constrained to specific proxy techniques and can obfuscate relayed traffic with a number of evasion tactics. Packet-based methods are computationally expensive, with scalability and false-positives being a problem for large networks.

%\textcolor{black}{All these examples demonstrate that stepping-stones are an important and challenging research problem. 
%Pivoting attacks are facilitated and the complexity of their detection is aggravated by various factors: the large number of heterogeneous host activities and the hundreds of thousands of communications occurring every day in any medium-large enterprise, which are difficult to analyse and may ease attackers evasion; the risk of false alarms because some activities detected as pivoting may be benign, such as SSH tunnels created by network administrators.}

%Malicious actors on the Internet frequently use chains of compromised hosts to relay their attack, in order to obtain access to restricted resources and to reduce the chance of being detected. These hosts, called \textbf{stepping-stones}, are used by the attacker as relay machines, to which they maintain access using tools such as SSH or Telnet. 


%Stepping-stone detection (SSD) primarily looks at network traffic, with many approaches aiming to identify potential correlation between two connections going from or to a particular host.

%There are a number of approaches to detect stepping-stones, with the earliest one having been proposed by Staniford and Heberlein in 1995 \textcolor{red}{citation needed?}. 



Like many intrusion attacks, stepping-stones are rare and there exists no public data representing real stepping-stone behaviour, and researchers have to rely on synthetic data. Some attempts have been made to create publicly available stepping-stone testbeds, yet most researchers evaluate their SSD methods on self-provided data. The underlying traffic generation implementations often vary significantly, which makes a direct comparison of the achieved results impossible. 

In this work, we provide the following contributions:

\begin{enumerate}
\item We describe a framework to generate data that represents realistic stepping-stone data without bias to particular detection mechanisms. Our framework is scalable and capable of generating sufficient variety in terms of network settings and conducted activity. 
\item We release a large and comprehensive dataset suitable for the training of machine-learning-based methods and in-depth performance evaluation. To our knowledge, this is the first public SSD dataset.
%\item We surveyed the space of SSD methods carefully and selected eight methods that represent the current state-of-the-art according to three selection criteria.
\item We re-implemented eight SSD methods that represent the current state-of-the-art and provide a fair evaluation of their capabilities in a number of settings. 
%use this data to provide comparison of the capabilities of eight state-of-the-art stepping-stone detection methods that we re-implemented. Furthermore, we show that by inserting enough chaff perturbations in the right form, an intruder can evade all current SSD methods successfully.
\item Our evaluation shows that while most methods can accurately detect command propagation, detection rates plummet when appropriate chaff is inserted. This result disproves the claims made for multiple methods that their detection rates are robust against chaff perturbations.
\end{enumerate} %an independent framework to generate data that represents realistic stepping-stone data. Our framework is scalable and capable of generating sufficient variety in terms of network settings and conducted activity. This allows us to generate a large and comprehensive dataset suitable for the training of ML-based methods and in-depth performance evaluation. We use this data to provide comparison of the capabilities of eight state-of-the-art stepping-stone detection methods that we re-implemented. Furthermore, we show that by inserting enough chaff perturbations in the right form, an intruder can evade all current SSD methods successfully.

%\textcolor{red}{add contributions here}
The rest of the paper is organised as following: Section \ref{Sec:Introduction} provides an introduction and background to the problem of stepping-stone detection. Section \ref{Sec:Datasetcreation} discusses the particular design of the data generation framework.
Section \ref{Sec:Evaldata} presents the dataset arrangement in terms of background and attack data and discusses evaluation methods. Section \ref{Sec:Selection} discusses the selection process, properties, and implementation of the eight SSD methods that we implemented for evaluation. Section \ref{Sec:Results} discusses the results achieved by the implemented methods on the given data. Section \ref{Sec:Relatedwork} discussing related work.

\subsection{Background}


%Stepping-stone detection (SSD) primarily looks at network traffic, with many approaches aiming to identify potential correlation between two connections going from or to a particular host.
%There are a number of approaches to detect stepping-stones, with the earliest one having been proposed by Staniford and Heberlein in 1995 \textcolor{red}{citation needed?}. Like many intrusion attacks, stepping-stones are rare and there exists no public data representing real stepping-stone behaviour, and researchers have to rely on synthetic data. Some attempts have been made to create publicly available stepping-stone testbeds, but most researchers evaluate their SSD methods on self-provided data. The underlying traffic generation implementations often differ significantly, which makes a direct comparison of the achieved results impossible. Additionally, we find that implemented evasive behaviours are often too simplistic and thus increase detection rates. 
 
%When a person logs into one computer and from there logs into another computer and so on, we refer to the sequence of logins as a connection chain. 
Stepping-stones were first conceptualised by Staniford-Chen and Heberlein in 1995 \cite{staniford1995holding}. In an interactive stepping-stone attack, an attacker located at the origin host, which we call \textit{host O}, sends commands to and awaits their response from a target, \textit{host T}. The commands and responses are proxied via a chain of one or more intermediary stepping-stone hosts, which we call \textit{host} $S_1$, \dots, $S_N$, such as depicted in Fig. \ref{Fig:Stepstone}. 
Once a host $S_i$ is brought under control, it can be turned into a stepping-stone with simple tools and steps. Some of the most common set-ups are port forwarding via SSH-tunnels, setting up a backpipe with NetCat, or using metasploit to set up a SOCKS proxy \cite{pivoting2015}.
% typically by using terminal emulation programs like TelNet or SSH, or via backdoors using tools such as Netcat \textcolor{red}{reference}. These commands and responses are 

Typically, host O is located outside the targeted network, and the attack is started by compromising an initial foothold $S_i$ inside the network, from wich the attacker tries to move deeper into the network to reach the most valuable target $T$ \cite{Mandiant2015trends}. The attacker may use one or more compromised intermediary hosts $S_1,\dots, S_{i-1}$ outside the target network at different geographical locations in order to make tracing back the attack impossible. 

\begin{figure}
\centering
\includegraphics[width=0.85\textwidth]{images/Stepstone_final.png}
\caption{Depiction of an exemplary stepping-stone chain.}\label{Fig:Stepstone}
\end{figure}

%\textcolor{red}{another popular way is using netcat}

%However, detecting that a host is used in a stepping-stone chain is a clear indication of malicious behaviour. If a stepping-stone can be identified during the attack stage, the connection can be terminated to interrupt the attack. 
Stepping-stone detection (SSD) is a process of observing all incoming and outgoing connections on a particular host $h_i$ and determining whether it is used to relay commands. This is generally done with no prior information about any other stepping-stone hosts $S_1,\dots\,S_N$ or the endpoints $O$ and $T$. Once $h_i$ is known to be a stepping-stone host, further members of $\{S_1,\dots\,S_N\}$ can be traced back from $h_i$.   %This problem is closely related to the problem of tracing intruders through the Internet by following the connection chain. 

A popular approach to SSD is to compare connections pairwise to identify whether they carry the same information. A wide-spread way to achieve this is via \textit{watermarking}, an active SSD mechanism. A watermark is a unique binary string, which is usually embedded into a connection by altering the packet interarrival times. Decoding the watermark involves capturing candidate flows that might match the water-marked flow and looking for the bits in the flow characteristics.
Popular passive SSD methods are based on \textit{packet-correlation} and attempt to identify packets that appear in both connections. Since connections can be encrypted, this is often done by comparing sequences of interarrival times, packet sizes, and the overall number of packets in each connection.

Another prominent approach to detect stepping stones is based on \textit{round-trip-times} (RTTs). The RTT of a connection is the time it takes for a packet to be sent to the receiver plus the time it takes for an acknowledgement of that packet to be received. Since information is relayed over one or more hosts in a stepping stone chain, this has an effect on the overall RTTs which can be observed within individual connections in the chain.
%\subsubsection{Detecting Connection-Chains: A Data Mining Approach, 2010}

Anomaly-based methods aim to detect the insertion of time delays and chaff perturbations in a connection as deviations from typical TCP-behaviour to indicate of suspicious behaviour. 



% typically either aims at classifying a host as a stepping stone if two connections involving this host appear to be correlated, or at classifying a connection as part of a chain if it shows characteristic side-effects of relay behaviour. Among 

%Popular SSD methods include watermarking, where the re-occurrence of an artificially embedded flow pattern  
%is to measure the \textcolor{red}{...}

%In addition, several SSD methods aim to estimate the overall length of the stepping-stone chain from the examined connection to help tracing the chain. %A traffic collection sensor is typically placed in the vicinity of the examined host to provide the necessary data. 



To avoid detection, several evasive flow transformation techniques exist that aim at decreasing observable correlation between two connections in a chain. 

\begin{itemize}

\item \textbf{Packet transfer delays/drops}: An attacker can choose to apply artificial delays to forwarded packets, or drop certain packets to cause retransmission, in order to creates temporal disparity between connections. Researchers often assume the existance of a maximum tolerable delay \cite{donoho2002multiscale}.

%An easy way for an attacker to destroy flow watermarks and create temporal disparity between connections is to apply artificial random delays to forwarded packets, often also called jitter. Similarly, an attacker can choose to not forward certain packets at all and cause retransmissions. Researchers often assume the existance of a maximum tolerable delay for an attacker.

\item \textbf{Chaff perturbations}: Chaff packets are packets without meaningful content that are added to individual connections in a chain without being forwarded, and cannot be distinguished from real attack packets by a third party. Adding chaff perturbations alters the overall amount of traffic in a connection and can be used to shape the connection profile towards other traffic types. 

\item \textbf{Repacketisation}: Repacketisation is the practice of combining closely adjacent packets into a larger packet, splitting a packet into multiple smaller packets, or altering the packet content to change observed packet sizes and numbers.

\item \textbf{Flow splitting/merging}: Since SSD is mostly done on singular connections, an attacker can split the flow of packets to two or more connections and merge them at the target. 

\end{itemize}

In our evaluation, we set out to understand the effect of different evasive methods on detection rates. 

\section{Data generation setting}\label{Sec:Datasetcreation}

Our goal is to simulate data that reflects the different aspects of interactive stepping-stone behaviour in a reproducible manner. For a fair and thorough evaluation, we want to cover different settings and interactions to incorporate enough variation in the data to highlight strengths and weaknesses of different SSD methods. %Furthermore, we need to generate sufficient data to effectively train some of the included methods. 


\subsection{Containerisation}

In order to consider all these factors, we rely on the virtualisation of networks using containerisation. A container is a standard unit of software that runs standalone in an isolated user space in order to remove platform dependencies. Compared to virtual machines, containers are more lightweight, always start from an identical state, and are highly specialized in their purpose with each container running only a specific piece of software or application. 

The advantages of containers over virtual machines enable us to easily control, modify, repeat, and scale a network of hosts while emulating different network settings. The use of containerisation for this project is a continuation of a traffic generation paradigm designed for machine learning, which was originally introduced in [citation currently blinded]. We build our traffic generation framework on the popular containerisation platform \textit{Docker} \textcolor{red}{citation needed?}.

%packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings.

%In contrast to standard virtual machines, containers forego a hypervisor and the shared resources are instead kernel artifacts, which can be shared simultaneously across several containers. Although this prevents the host environment from running different operating systems, containerization incurs minimal CPU, memory, and networking overhead whilst maintaining a great deal of isolation. %\cite{kolyshkin2006virtualization}. 


%. Docker enables us to script the repeated creation of steppings-stone chains within a virtual network in a scalable manner while allowing us to emulate different network settings. %\textcolor{red}{while allowing network different settings}. 

%\textcolor{red}{can we cite DetGen here?}
%\textcolor{red}{write more about Docker advantages in terms of speed and controllability}

%We build our traffic generation framework on the popular containerisation platform \textit{Docker}. %Docker allows the creation of virtualised networks to which containers can connect via a virtualised network bridge. Containers attached to the bridge network are assigned an IP address and are able to communicate with other containers on their subnetwork.

\subsection{Simulating stepping stones with SSH-tunnels and Docker}\label{Sec:Setup}

We want to capture data not only from one interaction in a fixed stepping-stone chain, but from many interactions and chains with different settings. For that, we run multiple simulations, with each simulation establishing a stepping-stone chain and controlling the interactions between host O and host T. A simulation and the corresponding traffic capture is in a capture-script. 

A simulation begins with the start-up of the necessary containers and ends with their takedown. We represent host O, host T, and host $S_1,\dots,S_n$ with SSH-daemon containers. To establish a connection chain, we connect these containers via SSH-tunnels, with the first tunnel forwarding the required port from host O to host $S_1$, which is then forwarded to host $S_2$ by the second tunnel etc. As mentioned by Gordon Fraser \cite{pivoting2015}, this is one of the most common pivoting methods for attackers. Fig. \ref{Fig:Packetway} depicts a packet transfer via an exemplary chain. 


\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{images/Packetway.png}
\caption{Depiction of the way a command is packetised, encrypted, and travels through the different stages of the stepping-stone chain via SSH-tunnels.}\label{Fig:Packetway}
\end{figure}

Traffic is captured both at host $T$ and host $S_n$, which acts as the final stepping-stone in the chain.% and is most thus likely the target of a detection algorithm. 




%insert figure with one and with three stepping stones



%SSH tunnel on respective port on the starting point of the chain, tunnels to port on the next point in the chain. Finally, Refer to figure. 

\subsubsection{Simulating interactive SSH-traffic}\label{Sec:Simulating_interactive}

In order to generate enough data instances representing interactive stepping stone behaviour, we automatised the communication between host O and host T. For each simulation, we generate a script which passes SSH-commands from host O to host T.

For script-based session creation, several measures have been taken to make them realistic. First, each session tries to mimic a real user's action. We compiled a command database which consists of common commands and their usage frequency, similar to \cite{xin2006testbed}.% \cite{rossey2002lariat}. 
Commands are drawn randomly according to their usage frequency and concatenated to a script. 
Commands can either be atomic, such as "ls-la" or "pwd", or compound. Compound commands need additional input such as the directory and name of a specific file that is transferred, or input text to fill a file. The content and sometimes length of these inputs as well as transferred files are randomised appropriately when a compound command is drawn. Scripts are of varying length and end once the \textit{End}-command is drawn from the command catalogue. 


To simulate human behaviour that is reacting to the response from host T, all commands are separating by \textit{sleep}-commands for time $t$, which is drawn from a truncated Pareto-distribution. Paxson et al. \cite{paxson1995wide} have shown that interpacket spacings corresponding to typing and "think time" pauses are well described by Pareto distributions with a shape parameter $\alpha\approx 1.0$. We use a truncated distribution capped at $10$s to avoid infinite waiting times since we already included a mechanism to end a script. 



%\textcolor{red}{show exemplary script}.

%To do so, we generate a script with SSH-commands at the start of each \textcolor{red}{execution} that is passed and run by the \textcolor{red}{starting point} of the chain. The generated script consists of a sequence of ordinary SSH-commands \textcolor{red}{list them here?}, which are drawn randomly from a command catalogue and are each separated by \textit{sleep}-commands for a time $t$ that is drawn each time from a Cauchy-distribution. The average sleep-time is around \textcolor{red}{insert}. The length of the script is reached when the \textit{end}-command is drawn from the catalogue.
%To evaluate the stepping stone detection capabilities of different proposed methods, we created a \textcolor{red}{realistic dataset...}
%\textcolor{red}{Insert example}

%For script-based session creation, several measures havebeen taken to make them realistic. First, each session tries tomimic a real user’s action. All users of the scripts are real useraccounts in the clients. The users are divided into four groups:administrators, secretaries, programmers, and researchers. For each type of user, there is large command database which con-sists of the common commands and their historic frequency ofexp_version -exit 5.0if {$argc!=1} {send_user "usage: ftp-rfc \[#] \[-index]\n"exit}set file "rfc$argv.Z"set timeout 60spawn ftp ftp.uu.netexpect "Name*:"send "anonymous\r"expect "Password:"send "expect@nist.gov\r"expect "ftp>"send "binary\r"expect "ftp>"send "cd inet/rfc\r"expect "550*ftp>" exit "250*ftp>"send "get $file\r"expect "550*ftp>" exit "200*226*ftp>"closewaitsend_user "\nuncompressing file - wait...\n"exec uncompress $fileFig. 7. Example script for a TELNET session
%use [22]. A portion of the command database for programmersare shown in Table I. Each Expect script is associated witha user, and the commands within the script are drawn fromcorresponding database according to their frequency. Thereare two types of commands: atomic and compound. Atomiccommands only need the user type the command line andthe system will parse the command and print the output.Examples are “ls -la”, “pwd”. Compound commands requiremore interaction. A simple example is “mail xxxx”. After theuser enters “mail xxxx” and “Enter” key, the system promptsthe user to enter “subject”, content and “cc” field of the email.Second, the human typing simulation feature of Expect is usedfor all commands of users. Third, more than 50 human actorsfrom four classes were invited to our lab to generate certainstepping stone chains that were recorded by autoExpect.



\subsubsection{Simulating different network settings}\label{Sec:congestion}

Hosts in a stepping-stone chains can be separated by varying distances. Some may sit in the same LAN, while others may communicate via the Internet from distant geographical locations. The type of separation between two hosts influences the round-trip-time, bandwidth, and network reliability. 

Docker communication takes place over virtual bridge networks, so the throughput is far higher and more reliable than in real-world networks. %This level of speed and consistency is worrying for our purposes as packet timings will be largely identical on repeated runs of a scenario and any collected data could be overly homogeneous.
To retard the quality of the Docker network to realistic levels, we rely on the emulation tool Netem. Netem  is a Linux command line tool that allows users to artificially simulate network conditions such as high latency, low bandwidth, or packet corruption/drop in a flexible manner \cite{hemminger2005network}.

We apply Netem commands to the network interface of each container, which adds correlated delays to incoming and outgoing packets that are drawn from a normal distribution with mean $\mu$, variance $\sigma^2$, and correlation $\rho_1$. We furthermore apply correlated packet loss and corruption drawn from a binomial distribution with probability $p$ and correlation $\rho_2$. Lastly, we apply an overall limit $B$ on the bandwidth of container network interfaces.

To allow for different types of host separation, we set the network settings and bandwidth limit for each host container individually before each simulation, and draw each of the given parameters from a suitable distribution. This allows for some hosts to experience very fast and reliable communication while others experience more congested communication. %\textcolor{red}{(should I specify which one for each? Seems a bit much...)} %before each \textcolor{red}{run} to allow for a good amount of variation in the generated data.
We store the set parameters along with the collected traffic for each simulation to include the effect of network congestion in the evaluation. 

%providing us with the flexibility to set each container's network settings uniquely. 




%This script randomizes the values of each parameter, such as packet drop rate, bandwidth limit, latency, ensuring that every run of a scenario has some degree of network randomization if desired.


\subsection{Evasive tactics}

\subsubsection{Adding transfer delays}\label{Sec:delays_desc}

To increase detection difficulty, we add random transfer delays to individual packets forwarded by stepping stone hosts. This method, often called \textit{jittering}, can destroy time-based watermarks in packet flows and help decrease observable correlation between two connections. 

We add transfer delays to forward packets again by using NetEm. We draw delays for departing packets on a hosts from a uniform distribution, covering the interval $[0,\delta_D]$. This particular choice has been suggested by Padhye et al. \cite{padhye2010evading} in order to mimic the interarrival distributions of streaming services. The value of $\delta_D$ is fixed before each simulation and can be varied to allow for different degrees of packet jittering. 

%\textcolor{red}{insert citation} suggested to use significantly longer packet delays of several seconds to request packets and their answers in order to decrease temporal correlation between active periods in two connections.
As pointed out by Donoho et al. \cite{donoho2002multiscale}, excessively long delays often lead to difficulties in the TCP-protocol due to the significant increase of packet reordering and response time-outs. We set the maximum value for $\delta_D$ at $1500$ ms. As we will see in Section \ref{Sec:Results}, this is enough to render watermarking methods obsolete while flow decorrelation can be achieved more effectively by using chaff perturbations. 



\subsubsection{Adding chaff perturbation}\label{Sec:chaff_desc}

In addition to transfer delays, we insert chaff packets to individual connections in the chain to increase detection difficulty. These chaff packets do not contain actual information and act as noise to decorrelate individual connections in the chain. To add and filter packets in a connection, we open additional ports in each SSH-tunnel that are however not forwarded through the entire chain. This means that each chaff packet only appears in the connection it was inserted to, making the chaff perturbation in two different connections independent of each other. 
We then use a NetCat client containers to send and receive packets on the additional ports in both directions. %Figure \textcolor{red}{...} depicts this setup. 



%\textcolor{red}{add reference} to send data to both ports from either direction and collect it at the other side. 
Again,  Padhye et al. \cite{padhye2010evading} suggest to generate chaff in a way that mimics the flow characteristics of streaming services in order to both spread the added perturbations evenly across the connection and increase the difficulty of detecting the perturbation itself.
Therefore, the size of the transferred data is drawn from a truncated Lognormal-distribution with mean $\mu_C$ to mimic video-streaming traffic. Similarly, packets are sent in intervals of random length $\delta_c$ drawn from a uniform distribution that covers the interval $[\delta_c/2,\delta_c]$ to mimic a relatively constant packet flow, typical for video-streaming. By adjusting $\delta_C$, we can control the amount of chaff sent. 


\subsubsection{Repacketisation}

One benefit of using SSH-tunnels from an attackers perspective is that packets are not simply forwarded, but a tunnel acts as an independent encrypted TCP-connection along with independent packet confirmations and repacketisation.

\subsubsection{Flow splitting/merging}

None of the methods we encountered are currently capable of dealing with flow splitting or merging. We therefore did not implement this tactic as the results would be uninformative.


Fig. \ref{Fig:Simulation_setup} depicts the interplay of the different containers in our simulation.

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{images/Docker_framework.png}
\caption{Depiction the simulation setup for each host in the chain.}\label{Fig:Simulation_setup}
\end{figure}


%\subsection{HTTP-interactions}
 
%In order to provide an additional, different type of interaction between the \textcolor{red}{starting point} and \textcolor{red}{end point}, we directed HTTP traffic over the stepping stone chain. Here, the starting point hosts Scrapy, a web crawling service \textcolor{red}{insert citation}, that surfs the 1 million most popular website by clicking links on them. The requests are sent over the stepping stone chain to the web. 

%This type of traffic is not meant to necessarily represent realistic stepping stone behaviour, but to provide an additional source of interactive traffic that differs substantially from SSH in order to test detection methods from another angle.




%\begin{tabular}{r|cccc|cccc}
%\multicolumn{1}{r|}{ }&\multicolumn{4}{c|}{SSH}&\multicolumn{4}{c}{HTTP}\\
%bla& no pert.&var. delays&var. chaff&delay\&chaff & no pert.&var. delays&var. chaff&delay\&chaff \\
%\end{tabular}

%\begin{tabular}{r|cccc}
%\multicolumn{1}{r|}{ }&\multicolumn{4}{c|}{SSH}&\multicolumn{4}{c}{HTTP}\\
%SSH 1 node& no pert.&var. delays&var. chaff&delay\&chaff \\
%HTTP 1 node& no pert.&var. delays&var. chaff&delay\&chaff \\
%SSH 3 node& no pert.&var. delays&var. chaff&delay\&chaff \\
%HTTP 1 node& no pert.&var. delays&var. chaff&delay\&chaff \\
%\end{tabular}


 
%\cite{sommer_outside_2010}

%\subsection{Regular traffic congestion}

%Packet transmission in Docker's virtual network is almost instantaneous and not subject to transmission errors. 
%To emulate realistic traffic as close as possible, we add emulated traffic congestion in the form of packet delivery delays and packet losses. These are implemented between individual hosts using tc-netem.

%Delays are added to incoming and outgoing packets on each host individually, and are drawn from a normal distribution. The mean and standard deviation are drawn before each simulation for each host.

\section{Evaluation data}\label{Sec:Evaldata}

The quality of both the stepping-stone and background data is crucial for a fair evaluation. 

First of all, we want to look at a variety of attack scenarios to highlight the strengths and weaknesses of different approaches. We created three main attack datasets that contain different forms and amounts of evasive behaviour, and a smaller dataset to highlight the influence of different network settings and chain lengths. 
To present a valuable false positive test, we provide three datasets with benign background traffic. The first contains general real-world traffic, while the second and third contain benign data that bears similar traffic characteristics as the attack data. Furthermore, we need to generate sufficient data to effectively train some of the included methods. 

We now describe our data assembly in more detail.

\subsection{Stepping-stone data}

We generate stepping-stone data following the steps described in Section \ref{Sec:Datasetcreation}. We create our main datasets using a chain of four stepping-stones $S_1, S_2, S_3$, and $S_4$. We subdivide into three datasets according to the two discussed evasion tactics, transfer delays and chaff perturbations. We first capture data without either of these methods in \textbf{dataset A}. We then capture data once with added transfer delays with varying $\delta_D$ to control delays in \textbf{dataset B}, and once with added chaff perturbations of varying $\delta_C$ in \textbf{dataset C}. Each dataset contains 30.000 connection pairs. 
%Lastly, we capture data with delays and chaff added simultaneously, with both varying $\delta_D$ and $\delta_C$.

We furthermore create a smaller \textbf{dataset D} with differing numbers of stepping-stones (1,3,5, and 8 jumps) without evasive tactics to evaluate this effect on RTT-based methods. For every jump, we generated 1.000 connection pairs. 

For all datasets, we randomise and record network settings. In Section \ref{Sec:InfluenceNetwork}, we examine the effect of extreme network settings on detection rates. 
%Table \ref{Tab:MalData} provides a summary of the connection pair numbers in each part of the dataset.
%\begin{table}
%\centering
%\begin{tabular}{l|r}
%4 jumps&\# connection pairs \\ \hline
%No evasion& 30.000\\ \hline
%Delays& 30.000 \\ \hline
%Chaff&30.000 \\ \hline
%\hline
%1 jump& 1.000\\ \hline
%3 jump& 1.000 \\ \hline
%5 jump& 1.000 \\ \hline
%8 jump& 1.000 \\ \hline
%\end{tabular}
%\caption{Number of connection pairs in each part of the stepping-stone dataset.}\label{Tab:MalData}
%\end{table}

%Table \ref{Tab:Stepstone_data} depicts the number of connection pairs included in each dataset.

%\begin{table}
%\centering
%\begin{tabular}{r|c|c|c|c}
%\multicolumn{1}{r|}{ }&\multicolumn{4}{c|}{SSH}&\multicolumn{4}{c}{HTTP}\\
%nodes & no evasion & delays & chaff & delays\& chaff \\
%\hline
%1-node & 10.000 & 10.000 & 10.000 & 10.000 \\
%4-node & 10.000 & 10.000 & 10.000 & 10.000 \\
%\end{tabular} 
%\caption{}\label{Tab:Stepstone_data}
%\end{table}

 
\subsection{Benign data}

We need to provide a realistic background of benign data that reflects the heterogeneous nature of regular network traffic, both for evaluation of false positives and for the training of ML-based methods.

We include real-world traffic traces, taken from the \textbf{CAIDA} \textit{2018 Anonymized Internet Traces} dataset \cite{CAIDA2018}. This data contains traces collected from high-speed monitors on a commercial backbone link, and is often used for research on the characteristics of Internet traffic, including application breakdown, security events, geographic and topological distribution, flow volume and duration.
%\textcolor{red}{insert citation and description}.


The CAIDA dataset provides suitable general background traffic. However, to sufficiently test for false-positive, we need to include benign traffic that has similar characteristics to the attack traffic and was generated in a similar network environment, which the CAIDA dataset not necessarily provides. For that, we created a set of interactive SSH-connections that are conducted directly between the client and the server instead of via a stepping-stone. We follow the same procedure as described in Section \ref{Sec:Simulating_interactive} with the same randomised network congestion settings as described in \ref{Sec:congestion}. We then proceed to pair connections by random.

Additionally, we include a third type of benign traffic to test false-positives of methods aiming to spot chaff perturbations. Since we followed the findings of Padhye et al. \cite{padhye2010evading} to generate perturbations that resemble multimedia streams, we want to include actual multimedia streams. For that, we captured traffic from a server streaming video to a client. Video content is randomised and multiple values for the streaming quality are used.
The server and client are hosted in the same virtual Docker network with randomised network congestion settings. Again, we pair generated connections by random. However, for each pair the direction of the transfer has to be either to or from the common host to either resemble a client requesting two videos or a server sending to videos.

We merge the three datasets to create our benign background dataset, with the CAIDA part containing 60.000 connection pairs, while the other two each contain 20.000 connection pairs. 

% according to the following ratios:

%\begin{table}
%\centering
%\begin{tabular}{l|r}
%&\# pairs \\ \hline
%CAIDA& 60.000\\ \hline
%SSH& 20.000 \\ \hline
%multimedia& 20.000 \\ \hline
%\end{tabular}
%\caption{Ratio of traffic in the benign dataset.}\label{Tab:Benigndata}
%\end{table}


\begin{table}
\centering
\begin{tabular}{l|l|l|l}
& Label  &Nr. of conn. & Purpose\\ \hline
\multirow{5}{*}{SS data}& set A & 30,000& \makecell[l]{Baseline attack data without\\evasion tactics} \\ \cline{2-4}
						& set B & 30,000& Inclusion of delays with varying $\delta_D$ \\ \cline{2-4}
						& set C & 30,000& Inclusion of chaff with varying $\delta_C$ \\ \cline{2-4}
						& set D & 40,000& \makecell[l]{Data from chains of different\\lengths,  no evasion tactics} \\ \hline
\multirow{5}{*}{Benign data}&CAIDA & 60,000& General background data \\ \cline{2-4}
							&SSH & 20,000& \makecell[l]{Background data similar to\\attack commands} \\ \cline{2-4}
							&Multimedia & 20,000& \makecell[l]{Background data similar to\\chaff perturbations} \\ \hline
\end{tabular}
\caption{Summary of different components in our evaluation data.}\label{Fig:Datasim}
\end{table}



We are aware that the amount of interactive SSH traffic and multimedia streams in this setting is inflated from a realistic setting, but we believe that this setting is more suitable to highlight the strengths and drawbacks of SSD methods. In the evaluation, we will also state individual false positives for each of the three datasets to indicate which type of traffic present the biggest challenge for the selected SSD methods. Table \ref{Fig:Datasim} summarises the different parts in our evaluation data.

%\begin{figure}
%\begin{tikzpicture}[
%    grow=right,
%    level 1/.style={sibling distance=6cm,level distance=3.2cm},
%    level 2/.style={sibling distance=1.8cm, level distance=4.5cm},
%    edge from parent/.style={very thick,draw=blue!40!black!60,
%        shorten >=5pt, shorten <=5pt},
%    edge from parent path={(\tikzparentnode.east) -- (\tikzchildnode.west)},
%    kant/.style={text width=2cm, text centered, sloped},
%    every node/.style={text ragged, inner sep=2mm},
%    punkt/.style={rectangle, rounded corners, shade, top color=white,
%    bottom color=blue!50!black!20, draw=blue!40!black!60, very
%    thick }
%    ]
%
%\node[punkt, text width=5.5em] {\textbf{Evaluation data}}
%    %Lower part lv1
%    child {
%        node[punkt] [rectangle split, rectangle split, rectangle split parts=2,
%         text ragged] {
%            \textbf{Benign data}
%                  \nodepart{second}
%            100,000 connect.
%        }
%		child {
%            node [punkt, rectangle split, rectangle split parts=2]{
%                \textbf{Video streaming}
%                \nodepart{second}
%                similar to chaff, 20,000
%            }
%            edge from parent
%                node[kant, above] {}}
%		child {
%            node [punkt,align=left, rectangle split, rectangle split parts=2]{
%                \textbf{interactive SSH}
%                \nodepart{second}
%                similar to attack\\ commands,  20,000
%            }
%            edge from parent
%                node[kant, above] {}}
%        child {
%            node [punkt, rectangle split, rectangle split parts=2]{
%                \textbf{CAIDA}
%                \nodepart{second}
%                gen. background, 60,000
%            }
%            edge from parent
%                node[kant, above] {}}
%        edge from parent
%            node[kant, below, pos=.6] {}
%    }
%    %Upper part, lv1
%    child {
%        node[punkt, rectangle split, rectangle split parts=2] {
%	\textbf{SS data}
%                \nodepart{second}
%                94,000 connect.
%        }
%		child {
%            node [punkt, rectangle split, rectangle split parts=2]{
%                \textbf{set D}
%                \nodepart{second}
%                mult. jumps, 4,000
%            }
%            edge from parent
%                node[kant, above] {}}
%        child {
%            node [punkt, rectangle split, rectangle split parts=2]{
%                \textbf{set C}
%                \nodepart{second}
%                chaff, 30,000
%            }
%            edge from parent
%                node[kant, above] {}}
%		child {
%            node [punkt, rectangle split, rectangle split parts=2]{
%                \textbf{set B}
%                \nodepart{second}
%                delays, 30,000
%            }
%            edge from parent
%                node[kant, above] {}}
%         child {
%            node [punkt,rectangle split, rectangle split,
%            rectangle split parts=2] {
%                \textbf{set A}
%                \nodepart{second}
%                no evasion, 30,000
%            }
%            edge from parent
%                node[below, kant,  pos=.3] {}}
%            edge from parent{
%                node[kant, above] {}}
%    };
%\end{tikzpicture}
%\caption{Summary of different components in our evaluation data.}\label{Fig:Datasim}
%\end{figure}

\subsection{Data preparation}


We group packets to connections according to the usual 5-tuple consisting of \{Src. IP, Dst. IP, Src. port, Dst. port, IP protocol\}. We select and pair TCP-connections at random to make %100.000 
connection pairs. 

Different approaches require different amounts of packets to make predictions. To create a fair playing field, we only look at connections that exchange more than 1500 packets and exclude shorter connections from both the background data. This number seems like a suitable minimal limit for a successful interactive stepping-stone chain as all of the selected methods are supposed to make successful detection with less packets, and there were no connections with less packets in the stepping-stone dataset. %\textcolor{red}{add validation about how this is sufficient for all approaches?}. 
The first 1500 packets are then passed to each SSD method to make a prediction.

The initialisation of the SSH-tunnels usually follows a distinct pattern that can be learned and consequently boost detection rates for ML-based methods. Since this pattern is not necessarily representative of actual stepping-stone behaviour, we remove the first thirty packets of all captured connections. If necessary, we also remove the last thirty packets to avoid the same issue for connection closures. 

%\subsection{Evaluation methods}

All of the above presented methods classify individual connections or pairs of connections as malicious or benign. True stepping stone connections are rare compared to benign ones, making their detection an imbalanced classification problem. An appropriate measure to evaluate SSD methods are false positive and false negative rates as well as the \textit{Area-under-ROC-curve} (AUC) for threshold-based methods.


\section{Selected SSD methods and Implementation}\label{Sec:Selection}

The main contribution of this work is to offer a modern evaluation of the current state of SSD methods. A range of underlying techniques exist for SSD, and we try to include approaches from every area to create an informative overview and highlight strengths and weaknesses. 

We surveyed publications to create a collection of SSD methods. We started with the publications from surveys \cite{shullich2011survey,wang2018research}, and then added impactful recent publications found via Google Scholar\footnote{keywords ``connection'', ``correlation'' ``stepping-stone'', ``detection'', ``attack'', ``chaff perturbation''}.
% from 2018 and 2011, mentioned in Section \ref{Sec:Relatedwork}. We expanded this collection via finding publications that cited these papers. Lastly, we found publications by browsing Google Scholar with different combinations of the keywords ``connection'', ``correlation'' ``stepping-stone'', ``detection'', ``attack'', ``chaff perturbation''. Our final collection contained 60 publications. 

From here, we selected approaches based on the following criteria:


\begin{enumerate}
\item The achieved detection and false positive rates claimed by the authors,
\item and whether the model design shows robustness against any evasion tactics as claimed by the authors.
\item We always selected the latest versions if a method has been improved or updated by the authors.
\end{enumerate}


Below, we describe the selected methods. Table \ref{Tab:Summary} contains a summary of the included methods. We labelled each method to make referring to it in the evaluation easier.

\begin{table}
\centering
\begin{tabular}{l|c|c|c|c|c}
Category & Approach & TP & FP & Robustness & Label\\ \hline

Packet-corr. & Yang, 2011 \cite{yang2011correlating} & $100\%$ & $0\%$& jitter/$<80\%$ chaff & PContext\\ \hline

\multirow{2}{*}{Neural networks} & Nasr, 2018 \cite{nasr2018deepcorr} &$90\%$ & $0.0002\%$& small jitter & DeepCorr\\ \cline{2-6}
 
 & Wu, 2010 \cite{wu2010neural} & 100\% & 0\% & - & WuNeur\\ \hline
 
\multirow{2}{*}{RTT-based} & Yang, 2015 \cite{yang2015rtt}& \multicolumn{2}{c|}{not provided} & $50\%$ chaff &RWalk\\ \cline{2-6}

& Huang, 2016 \cite{huang2016detecting} & $85\%$ & $5\%$ & - & Crossover\\ \hline
 
\multirow{2}{*}{Anomaly-based} & Crescenzo, 2011 \cite{di2011detecting} & $99\%$ & $1\%$ & jitter/chaff &Ano1\\ \cline{2-6}

& Huang, 2011 \cite{huang2011detecting,ding2013detecting} & $95\%$ & $0\%$ & $>25\%$ chaff/ $>0.2$s jitter &Ano2\\ \hline

Watermarking & Wang, 2011 \cite{wang2010robust} & $100\%$ & $0.5\%$ & $<1.4$s jitter & WM\\ \hline
\end{tabular}
\caption{Summary of included SSD-methods along with the claimed true positive and false positive rates and evasion robustness by the corresponding authors. We added labels to each method for later reference.}\label{Tab:Summary}
\end{table}


%We believe that these criterias are sufficient to 

%Researchers have so far proposed two main approaches: passive monitoring and active perturbation. In the latter

%\subsubsection{Detecting Connection-Chains: A Data Mining Approach, 2010}


%TPR 100\% and FPR 0\%

\subsubsection{PContext, 2011}

Yang et al. \cite{yang2011correlating} compare sequences of interarrival times in connection pairs to detect potential stepping-stone behaviour. For that, the context of a packet is defined as the packet interarrival times around that packet. The context of packets is extracted from each connection, and their respective contextual distance is estimated using the Pearson correlation. %Packets with high correlation are defined as `matched', and two connections are classified as relayed if the ratio of matched packets exceeds a threshold. 
The authors propose to only collect interarrival times from \textit{Echo}-packets instead of \textit{Send}-packets to resist evasion tactics such as chaff and jitter.%, as the sending of \textit{Echo}-packets is subject to more constraints and less easy to manipulate.
The authors evaluate their results on connection pairs with up to $100\%$ chaff ratio, with the model being able to successfully detect connection relays in all cases. 


%\subsection{Neural networks}

%The authors present two networks to identify stepping stones. 
%The first method uses eight packet variables of an individual packet as input to predict the number of stepping-stones.




\subsubsection{WuNeur, 2010}

A notable initial example of neural network applications to SSD came from Wu et al. \cite{wu2008performance}, and which was later improved by the authors \cite{wu2008performance}.
%however, the authors concluded that the achieved results did not improve existing detection rates. but no good results, better in Neural networks-based detection of stepping-stone intrusion.
The designed neural network model is based on sequences of RTTs. For this, a packet matching algorithm is used to compute RTTs, which are then fed as a fixed-length sequence into a feed-forward network to predict the downstream length of the chain. The network itself only contains one hidden layer and is relatively small. RTT-based methods achieves good results only if RTTs are small, i.e. the stepping-stone chain is completely contained within one LAN-network.


\subsubsection{DeepCorr, 2018}

A more recent example of neural network application comes from Nasr et al. \cite{nasr2018deepcorr}, who train a deep convolutional neural network to identify correlation between two connections from the upstream and downstream interarrival times and packet sizes in each connection. The trained network is large, with over 200 input filters and consists of three convolutional and three feed-forward layers. The trained model was initially applied to a dataset of Tor-connections as well, where the authors achieved strong results. 
The authors achieve a $90\%$ detection rate with $0.02 \%$ false positives. 


\subsubsection{RWalk, 2015}


This model by Yang et al. \cite{yang2015rtt} combines packet-counting methods and RTT mining methods to improve detection results from \cite{yang2007mining}. 
%A widely-used approach is to compare the number of incoming packets in one connection with the number of outgoing packets in another connection to determine if the pair represents a stepping stone relay. However, the insertion of chaff can separate these numbers substantially.
The authors improve widely-used packet-counting methods to resist chaff perturbation by counting the number of round-trips in a connection to determine if the connection is being relayed.
%To resist intruders evasion, the authors propose to use the 
Packet pairs representing a round-trip for each connection are estimated using a combination of packet matching and clustering, and counted as $N_{in}$ and $N_{out}$. The authors then claim that the value of $N_{in}-N_{out}$ is only bounded if the two connections are relayed.

\subsubsection{C.Over, 2016}

This method by Huang et al. \cite{huang2016detecting} improves the detection methods proposed by Ding et al. \cite{ding2009detecting}. The authors target relayed interactive SSH communication at the end of a connection chain. Their detection model is built on the fact that in a long connection chain, the round-trip-time of a packet may be longer than the intervals between two consecutive keystrokes. %Normally after sending a request packet, a client will wait for the server response before sending another request. 
%TCP/IP allows a client to send a limited number of packets to the server without having to wait for the response. 
In a long connection chain, this will result in cross-overs between request and response, which causes the curve of sorted upstream RTTs to rise more steeply than in a regular connection. %A stepping stone is detected if the maximum increase in the curve exceeds a threshold. 
The authors do not state a universal threshold value and instead suggest a method to estimate the appropriate value for a given setting.
%Detecting Stepping-Stone Intruders by Identifying Crossover Packets in SSH Connections

%.

%.

%RTT-based Random Walk Approach to Detect Stepping-Stone Intrusion 

%Detecting Stepping-Stone Intruders with Long Connection Chains? 2009



\subsubsection{Ano1, 2011}

Crescenzo et al. \cite{di2011detecting} have proposed an assembly of three anomaly-based methods to detect time delays and chaff perturbations in a selected connection. 
A response-time based method is targeted at detecting packet time-delays by flagging acknowledgement packets if their response-time exceeds the average RTT by a fixed threshold. A distance-based method compares the similarity of downstream with upstream packet sequences in order to detect inserted chaff packets. Finally, a causality-based method verifies that the number of ON-intervals in upstream and downstream direction match each other to detect chaff.
The authors claim successful detection for chaff ratios 25\% or more, and for delays introduced to up to 70\% of all packets.

%. It estimates the RTT of a connection, and then flags acknowledgement packets if their response-time exceeds (RTT+$\delta_{RT}$). The authors claim that an attacker would have to impose delays on more than 70\% of all packets to evade this method.
%\item The edit-distance based method is comparing packet sequences ON-OFF intervals in upstream and downstream in a connection, which should be similar to each other in a benign connection. The assumption is that chaff insertation is often independent in the two directions, leading to dissimilarities. 
%\item The causality-based method is verifying that the number of ON-intervals in upstream and downstream direction match each other to detect chaff.
%\end{enumerate}

\subsubsection{Ano2, 2011/2013}
Huang et al. \cite{huang2011detecting} proposed an anomaly-based method to detect chaff perturbations based on their assessment that interarrival times in regular connections tend to follow a Pareto or Lognormal distribution, which chaffed connections supposedly do not. The authors extract packet interarrival times and calculate statistical score describing the fit to the distributions that is used to classify connections into normal and chaffed connections.
A similar approach from the same authors \cite{ding2013detecting} is directed towards the detection of packet jittering.
The authors achieve $95\%$ detection rate on connections with $50\%$ chaff ratio and more while retaining zero false positives using a small set of chaffed interactive SSH stepping-stone connections.
% generate a small set of chaffed interactive SSH stepping-stone chains, where they achieve a $95\%$ detection rate on connections which are subject to a $50\%$ chaff ratio while retaining zero false positives. For lower chaff ratios, the detection rate decreases significantly. 

% Afterwards, the goodness-of-fit is tested using two statistical tests, which yield a \textit{disagreement-of-fit score}. If this disagreement score exceeds a threshold, which was determined from a set of know regular connections, the connection is seen as being subject to chaff perturbations. The authors generate a small set of chaffed interactive SSH stepping-stone chains, where they achieve a $95\%$ detection rate on connections which are subject to a $50\%$ chaff ratio while retaining zero false positives. For lower chaff ratios, the detection rate decreases significantly. 

%A similar approach from the same authors \cite{ding2013detecting} is directed towards the detection of packet jittering. However, instead of estimating a disagreement-of-fit score, the authors use the estimated distribution parameters as input to train a support vector machine. 


%A watermark is simply an unique binary string. The process of embedding one bit of this string consists of changing some property, usually packet interarrivals, of a traffic flow such that the change represents a bit. Decoding the watermark involves capturing candidate flows that might match the water-marked flow and looking for the bits in the flow characteristics. The bits of the watermark should have enough redundancy to ensure that they are decoded correctly with high probability.

\subsubsection{WM, 2010}
Flow watermarking is the most effective way at correlating connections with low false positives. However, as found by \cite{iacovazzi2016network}, usually not very robust against timing and chaff perturbation attacks. We have selected the approach developed by Wang et al. \cite{wang2010robust} to be included in our evaluation because the authors state at least some resistance against timing perturbations. The authors assume some limits to an adversary's timing perturbations, such as a bound on the delays. The authors divide a sequence of packets into pairs, whose interarrival time is perturbed using a new watermarking function. The introduced watermark is invisible for third-parties, and % and can be decoded in packet sequences longer than 600 packets using $m=12$ when $s=400ms$. 
the authors achieve $100\%$ TP with $0.5\%$ FP while claiming resistance against timing perturbations of up to $1.4s$.

%two groups of length $m$, and match packets from both groups into pairs. Each pair interarrival time is then perturbed using a watermarking function in dependence of an overall perturbation value $s$. 
%The introduced watermark is invisible for third-parties and can be decoded in packet sequences longer than 600 packets using $m=12$ when $s=400ms$. The authors achieve $100\%$ TP with $0.5\%$ FP and claim resistance against timing perturbations of up to $1.4s$.


%Iacovazzi et al. \cite{iacovazzi2016network} found that flow watermarking is done overwhelmingly through 



%The false positive rate is defined as
%
%\begin{align*}
%\frac{\text{number of benign connections classified as malicious}}{\text{overall number of benign connections}},
%\end{align*}
%
%while the false negative rate is defined as
%
%\begin{align*}
%\frac{\text{number of malicious connections classified as benign}}{\text{overall number of malicious connections}}.
%\end{align*}
%
%Some methods additionally try to predict the length of the stepping stone chain.
%
%Write that we grant each method enough packets

\subsection{Implementation of selected approaches}

In order to evaluate the above selected method on our generated data, we had to reimplement the algorithms according to the steps and design described in the corresponding publications. We implemented all methods in Python, and PyTorch if necessary. To overcome unclear points or adjust to the new setting, we had to make a small number of judgement calls, the most important of which we mention here for completeness:

For all methods, either varied the particular separation threshold AUC calculation, or estimated it to yield a particular false positive rate across all methods. For both anomaly-based methods, we had to estimate multiple thresholds. We found appropriate values that yield the required FP rate and maximise the detection rate over all datasets via grid-search optimisation.


For the WM approach, we had to set the quantization step size $s=0.4$s, and the redundancy number $m=11$ to consistently embed the watermark in the first 1500 packets. These values were also used by the authors.

Both DeepCorr and WuNeur are machine-learning based algorithms, which need to be trained on appropriate training data before the evaluation. Since DeepCorr is a large model and requires a lot of training data, we train it using $80$\% of the evaluation data with the proportions described in Table \ref{Fig:Datasim}. WuNeur requires less amounts of training data and is more sensitive to differing chain lengths, which is why we use 1000 connection pairs from each dataset A,B,C, and D, as well as 6000 connection pairs from the training data. We train each method for 500 epochs. 


%\textcolor{red}{add short description how we trained approaches}

\section{Results}\label{Sec:Results}


\subsection{Data without evasion tactics}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}
\includegraphics[width=\maxwidth]{figure/Noevasion_4nodes-1} \caption[ROC-curves for different SSD methods on dataset A (no evasive tactics)]{ROC-curves for different SSD methods on dataset A (no evasive tactics). Anomaly-based methods are excluded.}\label{fig:Noevasion_4nodes}
\end{figure}


\end{knitrout}

\begin{table}
\centering
% latex table generated in R 3.5.3 by xtable 1.8-3 package
% Mon Apr 27 14:19:01 2020
\begin{tabular}{l|r|r|r|r|r|r}
  \hline
 & PContext & DeepCorr & WuNeur & RWalk & C.Over & WM \\ 
  \hline
AUC & 0.998 & 0.997 & 0.939 & 0.853 & 0.965 & 0.9998 \\ 
   \hline
\end{tabular}

\caption{AUC-scores for different methods on stepping-stone data without evasive tactics.}\label{Tab:dfAUC}
\end{table}

First, we look at the detection rates for traffic from stepping-stones that did not use any evasive tactics, i.e. $S_1,\dots,S_4$ are only forwarding the commands and responses. The successful detection of this tytpe of behaviour with low false-positives should be the minimum requirement for any of the selected methods except for the anomaly-based approaches. Since these aim to detect evasive behaviour, we exclude them from this analysis. 

To get clear picture of the capabilities of the selected methods, we look at the ROC-curve in Fig. \ref{fig:Noevasion_4nodes}, which plots the true positive rate against the false positive rate for various detection threshold settings. Table \ref{Tab:dfAUC} depicts the overall AUC-scores.


%\textcolor{red}{insert NN approaches trained without noise?}

Unsurprisingly, the watermarking method achieves already high detection results without any false-positives. Both the PContext and DeepCorr models start to yield good detection results of around $80\%$ at a FP rate lower than $0.1\%$, with the PContext method slightly outpacing the DeepCorr method. 

RTT-based methods seem to not perform as well compared to the other included methods, however the observed ROC curve seems to be in general in agreement of the stated detection rates. %\textcolor{red}{check this again}.



%A possible explanation could be that each 

\subsection{Delays}

We now consider the effect of transfer delays added by the attacker to packets on the detection rates. For that, we pick detection thresholds for each SSD methods corresponding to a FP rate of $0.4\%$ as most methods are able to achieve some detection results at this rate. 
We look at delays added to only to outgoing packets on $S_4$, the last stepping stone in the chain. Fig. \ref{fig:Delaydetection} depicts evolution of detection rates in dependence of the maximum delay $\delta_D$.


%\textcolor{red}{consider two types of delays?}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}
\includegraphics[width=\maxwidth]{figure/Delaydetection-1} \caption[Detection rates in dependence of $\delta_D$ for different methods on dataset B with a fixed FP rate of $0.4\%$]{Detection rates in dependence of $\delta_D$ for different methods on dataset B with a fixed FP rate of $0.4\%$.}\label{fig:Delaydetection}
\end{figure}


\end{knitrout}

As visible, both anomaly-based methods are capable of detecting added delays relatively reliably. Furthermore, both the detection rates of DeepCorr and the rtt-based C.Over only decrease slightly under the influence of delays. Detection rates for all other methods decrease significantly to the point where no meaningful predictions can be made. This is also reflected by the AUC-scores for traffic with $\delta_D=1000ms$, given in Table \ref{Tab:AUCdelays}. 

While the WM method is robust against transfer delays up to $\delta_D=500$ms, this value is smaller than the one claimed by the authors. This might however be a result of the slightly smaller quantisation step size that we used. It is surprising that the PContext method shows only little robustness against transfer delays, which contradicts the authors claims. A possible explanation is the false assumption that relying on \textit{Echo}-packets increases robustness, since we also successfully apply delays to them while additional non-delayed \textit{Echo}-packets are generated by the tunnels. 


\begin{table}
\centering
% latex table generated in R 3.5.3 by xtable 1.8-3 package
% Tue Apr 28 20:07:48 2020
\begin{tabular}{l|r|r|r|r|r|r|r|r}
  \hline
 & PContext & DeepCorr & WuNeur & RWalk & C.Over & Ano1 & Ano2 & WM \\ 
  \hline
AUC & 0.639 & 0.995 & 0.619 & 0.639 & 0.953 & 0.997 & 0.996 & 0.559 \\ 
   \hline
\end{tabular}

\caption{AUC-scores for SSD methods with added transfer delays at $\delta_D=1000ms$.}\label{Tab:AUCdelays}
\end{table}



\subsection{Chaff}

We now consider the effect of chaff perturbations added by the attacker to individual connections on the detection rates. Again we pick detection thresholds for each SSD methods corresponding to a FP rate of $0.4\%$.% as most methods are able to achieve some detection results at this rate. 

Chaff packets are added to both the connection between $S_3$ and $S_4$ as well as between $S_4$ and host $T$ as described in Section \ref{Sec:chaff_desc}. Fig. \ref{fig:Chaffdetection} depicts evolution of detection rates in dependence of the ratio of number of chaff packets to packets from the actual interaction.


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}
\includegraphics[width=\maxwidth]{figure/Chaffdetection-1} \caption[Detection rates in dependence of $\delta_C$ for different methods on dataset C with a fixed FP rate of $0.4\%$]{Detection rates in dependence of $\delta_C$ for different methods on dataset C with a fixed FP rate of $0.4\%$}\label{fig:Chaffdetection}
\end{figure}


\end{knitrout}

As visible, all methods struggle to detect stepping stones once the chaff packets become the majority of the transferred traffic. This is also evident from the AUC-scores given in Table \ref{Tab:AUCdelays}. Several approaches claimed to be resistent to chaff perturbations, however prior evaluations never looked at chaff ratios that exceed $100\%$. 

It is surprising that the anomaly detection methods do not perform better at detecting chaff perturbations. Chaff in both approaches was however evaluated with different traffic generation distribution and not compared against a background of traffic following a similar generation distribution, which could explain the disagreement between the results we are finding here. 



Overall, this result is in disagreement with the "robustness against chaff" claims made for four of the selected approaches, namely PContext, RWalk, Ano1, and Ano2.

\begin{table}
\centering
% latex table generated in R 3.5.3 by xtable 1.8-3 package
% Tue Apr 28 20:07:52 2020
\begin{tabular}{l|r|r|r|r|r|r|r|r}
  \hline
 & PContext & DeepCorr & WuNeur & RWalk & C.Over & Ano1 & Ano2 & WM \\ 
  \hline
AUC & 0.637 & 0.885 & 0.613 & 0.642 & 0.590 & 0.781 & 0.738 & 0.838 \\ 
   \hline
\end{tabular}

\caption{AUC-scores for SSD methods with added chaff at 300\% ratio.}\label{Tab:AUCchaff}
\end{table}


%\subsection{Combination of delays and chaff}


\subsection{False positives}

Table \ref{Tab:dfFP} depicts the relative contribution\footnote{after adjusting for their weight} at $FP=0.4\%$ of each of the three benign data types to the overall false positive rate. Most methods have more problems with the heterogeneous nature the CAIDA traces, with only PContext and DeepCorr seeing most false positives in the SSH traffic. 

The multimedia traffic is causing most problems for the anomaly-based methods, persumably because it follows a similar distribution as the generated chaff perturbations.
%All methods have little problems identifying the multimedia traffic as benign. 
\begin{table}
\centering
% latex table generated in R 3.5.3 by xtable 1.8-3 package
% Sat Apr 18 17:04:29 2020
\begin{tabular}{l|r|r|r|r|r|r|r|r}
  \hline
 & PContext & DeepCorr & WuNeur & RWalk & C.Over & Ano1 & Ano2 & WM \\ 
  \hline
CAIDA & 0.37 & 0.37 & 0.51 & 0.67 & 0.57 & 0.49 & 0.36 & 0.82 \\ 
  SSH & 0.52 & 0.46 & 0.22 & 0.23 & 0.32 & 0.08 & 0.00 & 0.12 \\ 
  multimedia & 0.11 & 0.17 & 0.27 & 0.10 & 0.11 & 0.43 & 0.64 & 0.06 \\ 
   \hline
\end{tabular}

\caption{Relative contribution in \% of different benign data to the FP rate.}\label{Tab:dfFP}
\end{table}

\subsection{Influence of chain length}

In this section, we look at the effect of differing chain lengths on the detection rates. We only focus on RTT-based methods here since the other methods do not seem to be significantly influenced. Since RTT-based methods aim to measure the effect of packets travelling via multiple hosts, it is unsurprising that they perform better at detecting longer chains. 

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}
\includegraphics[width=\maxwidth]{figure/Influencechainl-1} \caption[Detection rates in dependence of chain length for different methods on dataset D with a fixed FP rate of $0.4\%$]{Detection rates in dependence of chain length for different methods on dataset D with a fixed FP rate of $0.4\%$}\label{fig:Influencechainl}
\end{figure}


\end{knitrout}

%\textcolor{red}{add comparison of results at different positions}

Of the RTT-based methods, only C.Over was able to yield consistent detection rates under transfer delays. 
Interestingly, if the C.Over method is applied to connections between $S_3$ and $S_4$ instead of between $S_4$ and the target, detection rates decrease in the same manner as for other RTT-based methods. This is not surprising as the underlying assumption for robustness for this approach relies on Echo-packets not being delayed.


%\textcolor{red}{I could insert comparison of prediction accuracy on chain length}


\subsection{Influence of network settings}\label{Sec:InfluenceNetwork}

\begin{table}
\centering
\begin{tabular}{l|c|c|c|c|c|c}
& Value & \multicolumn{5}{c}{TP deviation from average}\\ \hline
 & &DeepCorr & WuNeur & RWalk& C.Over & WM \\ \hline
\multirow{2}{*}{RTT} & 5ms& $-0.2\%$ & $+41.3\%$& $-42.3\%$ & $-36\%$ & $+0.03\%$ \\ \cline{2-7}
 & 70ms & $-5.6\%$ & $-5.8\%$& $+35.1\%$ & $+51\%$& $-2.2\%$\\ \hline

\multirow{2}{*}{Packet loss} & $0\%$ & $+1.2\%$& $+1.3\%$ & $+2.1\%$ & $+4.3\%$ & $+0.02\%$\\ \cline{2-7}
 & $7\%$ & $-9.1\%$& $-1.1\%$ & $-3.1\%$ & $-7.3\%$ & $-9.7\%$\\ \hline

%\multirow{2}{*}{Bandwidth} & no limit& & & & \\ \cline{2-6}
% & 50 kb/s & & & & \\ \hline s
\end{tabular}
\caption{Influence of network congestion on detection rates at a fixed FP rate of $0.4\%$. The given percentages are describing the change of the detection rate under the given congestion setting when compared to the overall average.}\label{Tab:Congestion}
\end{table}

Finally, we look at the effect of different nework settings. We only show methods that show significant effects and omitted bandwidth from the evaluation as different values do not seem to have any effect on detection rates.

As visible in Table \ref{Tab:Congestion}, the three RTT-based methods show different responses to small/large average round-trip-times. While WuNeur, as expected from prior results, performs better in LAN settings, detection rates of the RWalk and C.Over methods are boosted by larger RTTs. All methods profit from lower packet losses.

\subsection{Summary}

Overall, detection rates on dataset A are mostly in line with the claimed capabilities except for RWalk, although detection rates are slightly lower than stated by most authors. Delay perturbation increases detection difficulty for most methods, except for Ano1, Ano2, and DeepCorr, which contradicts robustness claims for PContext and to some extend WM. Our inserted chaff perturbations however render detection impossible for all methods examined, which contradicts robustness claims for PContext, Ano1, Ano2, and RWalk, although the claims were made based on lower chaff levels than we tested. 

Unsurprisingly, longer chains yield higher detection rates for RTT-based methods. Different network transmission settings seem to have little influence on detection rates. 


\section{Related work}\label{Sec:Relatedwork}

\subsection{Testbeds and data}

In 2006, Xin et al. \cite{xin2006testbed} developed a standard test bed for stepping-stone detection, called \textit{SST}. 
The main objectives in the development of SST were to enable a reproducible evaluation of stepping stone chain detection algorithms with easy configuration, management and operation. The tool allows for an arbitrary number of intermediate hosts and generates scripts to mimic interactive SSH and TelNet connections. 
To insert time delays and chaff perturbations, the authors modified the OpenSSH protocol on the intermediary hosts. Delays can be drawn from a uniform distribution while chaff can be drawn from a Poisson or Pareto distribution. To our knowledge, SST has only been used for evaluation by Zhang et al. \cite{zhang2005stepping}, and is not available anymore. The authors give little details about the implemented evasive tactics.%\textcolor{red}{say something why evasion not sufficiently implemented}

Another approach to use publicly available data comes from Houmansadr et al. \cite{nasr2018deepcorr}. The authors use the well-known CAIDA anonymised data traces \cite{CAIDA2018} to evaluate different watermarking methods for SSD. To simulate stepping stone behaviour, packet delays and drops are imposed retroactively on selected connections using Laplace and Bernoulli distributions with different rates. While this procedure seems sufficient for the evaluation of watermarking methods, it falls short on simulating the effects of an actual connection chain and leaves out chaff perturbations. 

We find that when authors evaluate methods on self-generated data, tested evasive behaviours are often lacking analytical discussion and their implementation is too simplistic, leading to increased detection rates. An example of this can be seen in the evaluation of Ano1 \cite{di2011detecting}, where a standard option in netcat is used to generate chaff perturbations for evaluation, or for PContext \cite{yang2015rtt} where simulated chaff is added randomly after the traffic collection.% without consideration of the underlying generation model and its consequences to the detection rates. 
Furthermore, often a relatively low limit on the amount of inserted chaff perturbations is assumed without obvious reason, thus avoiding evaluation at higher ratios. None of the methods we reviewed evaluate at chaff ratios above $100\%$.

% \textcolor{red}{do we have to back this up with more than just one or two sentences in the discussion? takes up more space...}. 

\subsection{Surveys}
Wang et al. \cite{wang2018research} recently conducted an extensive survey of stepping stone intrusion detection. The authors group methods according to the respective methodology 
%\begin{itemize}
%\item content-thumbprint,
%\item time-thumbprint,
%\item packet counting,
%\item random-walk-based,
%\item cross-over packet-based,
%\item watermarking,
%\item network-based,
%\item and software-defined-networking-based, 
%\end{itemize} 
but do not cover graph-based methods such as \cite{gamarra2018analysis}, %or \cite{apruzzese2017detection}, 
or anomaly-based methods such as \cite{di2011detecting}.%, which are increasing in popularity recently.
The authors then proceed to explain the different methods and highlight their benefits and shortcomings as well as open problems. 
Shullich et al. \cite{shullich2011survey} in 2011 also conducted a survey on stepping stone intrusion detection. The authors perform a similar grouping of methods, but also discuss related work in evasion tactics and test frameworks. The authors furthermore give an outlook on areas for future research, such as hacker motivation, the cardinality problem when correlating connection pairs, the difficulty of tracing back chains through firewalls, the lack of real-world data examples, or detection in covert channels or protocols such as UDP. Both surveys neither provide an evaluation of detection rates nor a direct comparison of the rates achieved by the corresponding authors. 

%Padhye et al. \cite{padhye2010evading} in 2010 have proposed a packet buffering method to decorrelate packets in the input flow from the output flow. Using this technique and enough chaff packets, the authors generate a constant-rate flow that resembles multimedia streams such as Voice over IP. However, the authors only test their framework against watermark-based SSD methods. 

%Yang et al. \cite{yang2018sniffing} have recently 


%\cite{almulhem2007survey}

%Stepping Stone Detection Techniques: Classification and State-of-the-Art, bad though

%Metrics: A Study on the Performance Metrics forEvaluating Stepping Stone Detection (SSD)
%Stepping Stone Detection: Measuring the SSD Capability
\subsection{Areas not covered in this work}

A different direction in SSD that we did not discuss in this work focuses more on the general communication behaviour of selected hosts rather than individual connections. Features include the timely correlation of connecting IP-address on a selected host or unusual paths of simultaneously existing connections within a computer network. Notable examples include Apruzzese et al. \cite{apruzzese2017detection} and Gamarra et al. \cite{gamarra2018analysis}, who both use graph-based models of network connections to identify suspicious relay hosts.
Emulating these features realistically in network traffic datasets is difficult, and there exist little research on how strongly actual attack behaviour influences these features. Since our dataset focuses only on individual connections and corresponding evasion, we are not able to include behaviour-based approaches in our evaluation.

Coskun et al. \cite{coskun2007efficient} identify another form of stepping-stones called \textit{store-and-forward}, which transfer data within files in a non-interactive manner. Though harder to detect than interactive connections, this procedure limits the attackers ability to explore the target, which is why SSD research has been primarily concerned with interactive stepping-stones.


\section{Conclusion}

In this work, we set out to evaluate the state-of-the-art of SSD methods using a comprehensive data generation framework. Our framework simulates realistic stepping-stone behaviour with SSH-tunnels in different  settings. The implemented evasive perturbation tactics follow the findings of Padhye et al. \cite{padhye2010evading} to resemble streaming services, and are adjustable in volume. We released a large dataset that highlights multiple aspects in SSD, and is suitable to train ML-based methods. 

Overall, our results show that attackers can reliably evade detection by using the right type and amount of chaff perturbation, which disproves several claims made about the robustness against this evasive tactic. Although less significant, our implemented delay perturbations still affect detection rates for most methods, but are more visible to anomaly-based methods. 

Currently, it seems that watermarking methods are currently most suited at detecting simple stepping-stones in real-life deployment due to very low false-positives. The performance of DeepCorr indicates that deep neural networks show the most potential at detecting methods that are subject to chaff or delay perturbations if they are trained on suitable data, and area we believe is worth more exploration. We find that detection and false-positive rates for RTT-based methods are significantly lower than for other methods, which makes them less suitable as stand-alone solutions.

%\bibliographystyle{IEEEtranS}
\bibliographystyle{plain}
\bibliography{NDSSrefs}

\appendix




 

\end{document}
